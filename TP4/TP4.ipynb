{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "370ed31d-cfba-4ea8-a3ae-ad372d2c3527",
   "metadata": {},
   "source": [
    "##  Parte I: Análisis de la base de hogares y tipo de ocupación\n",
    " Ahora que ya están familiarizados con la Encuesta Permanente de Hogares\n",
    " (EPH) y la desocupación, vamos a complejizar un poco la construcción de las\n",
    " tasas del desempleo. Relacionaremos la información a nivel hogar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf06b97-1597-4025-9c33-6fdd0eff08c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm     \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3bfe7f4-7a76-4ece-ab06-4c32302ac5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bases Tizi\n",
    "base_ind_04_sucia = pd.read_stata(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP3\\Individual_t104.dta\")\n",
    "base_ind_24_sucia = pd.read_excel(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP3\\usu_individual_T124.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f896b031-4044-4742-b3fa-96614e307a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hog_04_sucia = pd.read_stata(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP4\\Hogar_t104.dta\")\n",
    "base_hog_24_sucia = pd.read_excel(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP4\\usu_hogar_T124.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c7a4ec-2882-4b4c-815b-54ebb0635766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bases Angie\n",
    "#base_ind_04_sucia = pd.read_stata(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP3\\Individual_t104.dta\")\n",
    "#base_ind_24_sucia = pd.read_excel(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP3\\usu_individual_T124.xlsx\")\n",
    "\n",
    "#base_hog_04_sucia = pd.read_stata(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP4\\Hogar_t104.dta\")\n",
    "#base_hog_24_sucia = pd.read_excel(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP4\\usu_hogar_T124.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3d604-56cb-463a-9bac-36b8674cc2e1",
   "metadata": {},
   "source": [
    "### PUNTO 1\n",
    "Exploren el diseño de registro de la base de hogar: a priori, ¿qué variables creen pueden ser predictivas de la desocupación y seria útil incluir para perfeccionar el ejercicio del TP3? Mencionen estas variables y justifiquen su elección."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908092ec-4393-45f9-8a75-51f1b6b3b377",
   "metadata": {},
   "source": [
    "### PUNTO 2\n",
    "Descarguen la base de microdatos de la EPH correspondiente al primer trimestre de 2004 y 2024 en formato .dta y .xls, respectivamente. La base de hogares se llama Hogar_t104.dta y usu_hogar_T124.xls, respectivamente. Eliminen todas las observaciones que no corresponden a los aglomerados de Ciudad Autónoma de Buenos Aires o Gran Buenos Aires y unan ambos trimestres en una sola base. Esto es, a la base de la encuesta individual de cada año (que usaron en el TP3) unan la base de la encuesta de hogar. Asegúrese de estar usando las variables CODUSU y NRO_Hogar para el merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87c3e870-92ab-4a0b-a74b-41a9bd70fe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['codusu', 'ano4', 'trimestre', 'nro_hogar', 'componente', 'h15', 'region', 'mas_500', 'aglomerado', 'pondera', 'ch03', 'ch04', 'ch05', 'ch06', 'ch07', 'ch08', 'ch09', 'ch10', 'ch11', 'ch12', 'ch13', 'ch14', 'ch15', 'ch15_cod', 'ch16', 'ch16_cod', 'nivel_ed', 'estado', 'cat_ocup', 'cat_inac', 'imputa', 'pp02c1', 'pp02c2', 'pp02c3', 'pp02c4', 'pp02c5', 'pp02c6', 'pp02c7', 'pp02c8', 'pp02e', 'pp02h', 'pp02i', 'pp03c', 'pp03d', 'pp3e_tot', 'pp3f_tot', 'pp03g', 'pp03h', 'pp03i', 'pp03j', 'intensi', 'pp04a', 'pp04b_cod', 'pp04b1', 'pp04b2', 'pp04b3_mes', 'pp04b3_ano', 'pp04b3_dia', 'pp04c', 'pp04c99', 'pp04d_cod', 'pp04g', 'pp05b2_mes', 'pp05b2_ano', 'pp05b2_dia', 'pp05c_1', 'pp05c_2', 'pp05c_3', 'pp05e', 'pp05f', 'pp05h', 'pp06a', 'pp06c', 'pp06d', 'pp06e', 'pp06h', 'pp07a', 'pp07c', 'pp07d', 'pp07e', 'pp07f1', 'pp07f2', 'pp07f3', 'pp07f4', 'pp07f5', 'pp07g1', 'pp07g2', 'pp07g3', 'pp07g4', 'pp07g_59', 'pp07h', 'pp07i', 'pp07j', 'pp07k', 'pp08d1', 'pp08d4', 'pp08f1', 'pp08f2', 'pp08j1', 'pp08j2', 'pp08j3', 'pp09a', 'pp09a_esp', 'pp09b', 'pp09c', 'pp09c_esp', 'pp10a', 'pp10c', 'pp10d', 'pp10e', 'pp11a', 'pp11b_cod', 'pp11b1', 'pp11b2_mes', 'pp11b2_ano', 'pp11b2_dia', 'pp11c', 'pp11c99', 'pp11d_cod', 'pp11g_ano', 'pp11g_mes', 'pp11g_dia', 'pp11l', 'pp11l1', 'pp11m', 'pp11n', 'pp11o', 'pp11p', 'pp11q', 'pp11r', 'pp11s', 'pp11t', 'p21', 'decocur', 'idecocur', 'rdecocur', 'gdecocur', 'pdecocur', 'adecocur', 'pondiio', 'tot_p12', 'p47t', 'decindr', 'idecindr', 'rdecindr', 'gdecindr', 'pdecindr', 'adecindr', 'pondii', 'v2_m', 'v3_m', 'v4_m', 'v5_m', 'v8_m', 'v9_m', 'v10_m', 'v11_m', 'v12_m', 'v18_m', 'v19_am', 'v21_m', 't_vi', 'itf', 'decifr', 'idecifr', 'rdecifr', 'gdecifr', 'pdecifr', 'adecifr', 'ipcf', 'deccfr', 'ideccfr', 'rdeccfr', 'gdeccfr', 'pdeccfr', 'adeccfr', 'pondih', 'pj1_1', 'pj2_1', 'pj3_1', 'idimpp']\n"
     ]
    }
   ],
   "source": [
    "# LIMPIO BASE INDIVIDUAL\n",
    "\n",
    "# me quedo solo con los valores de CABA y GBA\n",
    "base_ind_04_filtrada = base_ind_04_sucia.loc[base_ind_04_sucia['aglomerado'].isin(['Ciudad de Buenos Aires', 'Partidos del GBA'])]\n",
    "base_ind_24_filtrada = base_ind_24_sucia.loc[base_ind_24_sucia['AGLOMERADO'].isin([32, 33])]\n",
    "\n",
    "#Para poder unir sin problema, me aseguro que als variables esten en el mismo formato\n",
    "base_ind_04_filtrada.columns = base_ind_04_filtrada.columns.str.lower()\n",
    "base_ind_24_filtrada.columns = base_ind_24_filtrada.columns.str.lower()\n",
    "\n",
    "# concateno las bases\n",
    "base_ind_prelimpieza = pd.concat([base_ind_24_filtrada, base_ind_04_filtrada])\n",
    "print(base_ind_prelimpieza.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "642e442d-0b8f-4fdf-8f0b-9d7606b0c2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['codusu', 'ano4', 'trimestre', 'nro_hogar', 'realizada', 'region', 'mas_500', 'aglomerado', 'pondera', 'iv1', 'iv1_esp', 'iv2', 'iv3', 'iv3_esp', 'iv4', 'iv5', 'iv6', 'iv7', 'iv7_esp', 'iv8', 'iv9', 'iv10', 'iv11', 'iv12_1', 'iv12_2', 'iv12_3', 'ii1', 'ii2', 'ii3', 'ii3_1', 'ii4_1', 'ii4_2', 'ii4_3', 'ii5', 'ii5_1', 'ii6', 'ii6_1', 'ii7', 'ii7_esp', 'ii8', 'ii8_esp', 'ii9', 'v1', 'v2', 'v21', 'v22', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19_a', 'v19_b', 'ix_tot', 'ix_men10', 'ix_mayeq10', 'itf', 'decifr', 'idecifr', 'rdecifr', 'gdecifr', 'pdecifr', 'adecifr', 'ipcf', 'deccfr', 'ideccfr', 'rdeccfr', 'gdeccfr', 'pdeccfr', 'adeccfr', 'pondih', 'vii1_1', 'vii1_2', 'vii2_1', 'vii2_2', 'vii2_3', 'vii2_4', 'idimph']\n"
     ]
    }
   ],
   "source": [
    "# LIMPIO BASE HOGAR\n",
    "\n",
    "# me quedo solo con los valores de CABA y GBA\n",
    "base_hog_04_filtrada = base_hog_04_sucia.loc[base_hog_04_sucia['aglomerado'].isin(['Ciudad de Buenos Aires', 'Partidos del GBA'])]\n",
    "base_hog_24_filtrada = base_hog_24_sucia.loc[base_hog_24_sucia['AGLOMERADO'].isin([32, 33])]\n",
    "\n",
    "#Para poder unir sin problema, me aseguro que als variables esten en el mismo formato\n",
    "base_hog_04_filtrada.columns = base_hog_04_filtrada.columns.str.lower()\n",
    "base_hog_24_filtrada.columns = base_hog_24_filtrada.columns.str.lower()\n",
    "\n",
    "# concateno las bases\n",
    "base_hog_prelimpieza = pd.concat([base_hog_24_filtrada, base_hog_04_filtrada])\n",
    "print(base_hog_prelimpieza.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2d65175-1388-4c0c-9813-8e4c0165b9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['codusu', 'ano4', 'trimestre', 'nro_hogar', 'componente', 'h15', 'region', 'mas_500', 'aglomerado', 'pondera', 'ch03', 'ch04', 'ch05', 'ch06', 'ch07', 'ch08', 'ch09', 'ch10', 'ch11', 'ch12', 'ch13', 'ch14', 'ch15', 'ch15_cod', 'ch16', 'ch16_cod', 'nivel_ed', 'estado', 'cat_ocup', 'cat_inac', 'imputa', 'pp02c1', 'pp02c2', 'pp02c3', 'pp02c4', 'pp02c5', 'pp02c6', 'pp02c7', 'pp02c8', 'pp02e', 'pp02h', 'pp02i', 'pp03c', 'pp03d', 'pp3e_tot', 'pp3f_tot', 'pp03g', 'pp03h', 'pp03i', 'pp03j', 'intensi', 'pp04a', 'pp04b_cod', 'pp04b1', 'pp04b2', 'pp04b3_mes', 'pp04b3_ano', 'pp04b3_dia', 'pp04c', 'pp04c99', 'pp04d_cod', 'pp04g', 'pp05b2_mes', 'pp05b2_ano', 'pp05b2_dia', 'pp05c_1', 'pp05c_2', 'pp05c_3', 'pp05e', 'pp05f', 'pp05h', 'pp06a', 'pp06c', 'pp06d', 'pp06e', 'pp06h', 'pp07a', 'pp07c', 'pp07d', 'pp07e', 'pp07f1', 'pp07f2', 'pp07f3', 'pp07f4', 'pp07f5', 'pp07g1', 'pp07g2', 'pp07g3', 'pp07g4', 'pp07g_59', 'pp07h', 'pp07i', 'pp07j', 'pp07k', 'pp08d1', 'pp08d4', 'pp08f1', 'pp08f2', 'pp08j1', 'pp08j2', 'pp08j3', 'pp09a', 'pp09a_esp', 'pp09b', 'pp09c', 'pp09c_esp', 'pp10a', 'pp10c', 'pp10d', 'pp10e', 'pp11a', 'pp11b_cod', 'pp11b1', 'pp11b2_mes', 'pp11b2_ano', 'pp11b2_dia', 'pp11c', 'pp11c99', 'pp11d_cod', 'pp11g_ano', 'pp11g_mes', 'pp11g_dia', 'pp11l', 'pp11l1', 'pp11m', 'pp11n', 'pp11o', 'pp11p', 'pp11q', 'pp11r', 'pp11s', 'pp11t', 'p21', 'decocur', 'idecocur', 'rdecocur', 'gdecocur', 'pdecocur', 'adecocur', 'pondiio', 'tot_p12', 'p47t', 'decindr', 'idecindr', 'rdecindr', 'gdecindr', 'pdecindr', 'adecindr', 'pondii', 'v2_m', 'v3_m', 'v4_m', 'v5_m', 'v8_m', 'v9_m', 'v10_m', 'v11_m', 'v12_m', 'v18_m', 'v19_am', 'v21_m', 't_vi', 'itf', 'decifr', 'idecifr', 'rdecifr', 'gdecifr', 'pdecifr', 'adecifr', 'ipcf', 'deccfr', 'ideccfr', 'rdeccfr', 'gdeccfr', 'pdeccfr', 'adeccfr', 'pondih', 'pj1_1', 'pj2_1', 'pj3_1', 'idimpp', 'realizada', 'iv1', 'iv1_esp', 'iv2', 'iv3', 'iv3_esp', 'iv4', 'iv5', 'iv6', 'iv7', 'iv7_esp', 'iv8', 'iv9', 'iv10', 'iv11', 'iv12_1', 'iv12_2', 'iv12_3', 'ii1', 'ii2', 'ii3', 'ii3_1', 'ii4_1', 'ii4_2', 'ii4_3', 'ii5', 'ii5_1', 'ii6', 'ii6_1', 'ii7', 'ii7_esp', 'ii8', 'ii8_esp', 'ii9', 'v1', 'v2', 'v21', 'v22', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19_a', 'v19_b', 'ix_tot', 'ix_men10', 'ix_mayeq10', 'vii1_1', 'vii1_2', 'vii2_1', 'vii2_2', 'vii2_3', 'vii2_4', 'idimph']\n"
     ]
    }
   ],
   "source": [
    "# CONCATENO LAS BASES INDIVIDUAL Y HOGAR\n",
    "\n",
    "base_prelimpieza = pd.concat([base_ind_prelimpieza, base_hog_prelimpieza])\n",
    "base_prelimpieza = pd.merge(base_ind_prelimpieza, base_hog_prelimpieza)\n",
    "\n",
    "print(base_prelimpieza.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "279543ea-a35a-42ce-a0cb-98ebfe9a9dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['codusu', 'ano4_x', 'trimestre_x', 'nro_hogar', 'componente', 'h15', 'region_x', 'mas_500_x', 'aglomerado_x', 'pondera_x', 'ch03', 'ch04', 'ch05', 'ch06', 'ch07', 'ch08', 'ch09', 'ch10', 'ch11', 'ch12', 'ch13', 'ch14', 'ch15', 'ch15_cod', 'ch16', 'ch16_cod', 'nivel_ed', 'estado', 'cat_ocup', 'cat_inac', 'imputa', 'pp02c1', 'pp02c2', 'pp02c3', 'pp02c4', 'pp02c5', 'pp02c6', 'pp02c7', 'pp02c8', 'pp02e', 'pp02h', 'pp02i', 'pp03c', 'pp03d', 'pp3e_tot', 'pp3f_tot', 'pp03g', 'pp03h', 'pp03i', 'pp03j', 'intensi', 'pp04a', 'pp04b_cod', 'pp04b1', 'pp04b2', 'pp04b3_mes', 'pp04b3_ano', 'pp04b3_dia', 'pp04c', 'pp04c99', 'pp04d_cod', 'pp04g', 'pp05b2_mes', 'pp05b2_ano', 'pp05b2_dia', 'pp05c_1', 'pp05c_2', 'pp05c_3', 'pp05e', 'pp05f', 'pp05h', 'pp06a', 'pp06c', 'pp06d', 'pp06e', 'pp06h', 'pp07a', 'pp07c', 'pp07d', 'pp07e', 'pp07f1', 'pp07f2', 'pp07f3', 'pp07f4', 'pp07f5', 'pp07g1', 'pp07g2', 'pp07g3', 'pp07g4', 'pp07g_59', 'pp07h', 'pp07i', 'pp07j', 'pp07k', 'pp08d1', 'pp08d4', 'pp08f1', 'pp08f2', 'pp08j1', 'pp08j2', 'pp08j3', 'pp09a', 'pp09a_esp', 'pp09b', 'pp09c', 'pp09c_esp', 'pp10a', 'pp10c', 'pp10d', 'pp10e', 'pp11a', 'pp11b_cod', 'pp11b1', 'pp11b2_mes', 'pp11b2_ano', 'pp11b2_dia', 'pp11c', 'pp11c99', 'pp11d_cod', 'pp11g_ano', 'pp11g_mes', 'pp11g_dia', 'pp11l', 'pp11l1', 'pp11m', 'pp11n', 'pp11o', 'pp11p', 'pp11q', 'pp11r', 'pp11s', 'pp11t', 'p21', 'decocur', 'idecocur', 'rdecocur', 'gdecocur', 'pdecocur', 'adecocur', 'pondiio', 'tot_p12', 'p47t', 'decindr', 'idecindr', 'rdecindr', 'gdecindr', 'pdecindr', 'adecindr', 'pondii', 'v2_m', 'v3_m', 'v4_m', 'v5_m', 'v8_m', 'v9_m', 'v10_m', 'v11_m', 'v12_m', 'v18_m', 'v19_am', 'v21_m', 't_vi', 'itf_x', 'decifr_x', 'idecifr_x', 'rdecifr_x', 'gdecifr_x', 'pdecifr_x', 'adecifr_x', 'ipcf_x', 'deccfr_x', 'ideccfr_x', 'rdeccfr_x', 'gdeccfr_x', 'pdeccfr_x', 'adeccfr_x', 'pondih_x', 'pj1_1', 'pj2_1', 'pj3_1', 'idimpp', 'ano4_y', 'trimestre_y', 'realizada', 'region_y', 'mas_500_y', 'aglomerado_y', 'pondera_y', 'iv1', 'iv1_esp', 'iv2', 'iv3', 'iv3_esp', 'iv4', 'iv5', 'iv6', 'iv7', 'iv7_esp', 'iv8', 'iv9', 'iv10', 'iv11', 'iv12_1', 'iv12_2', 'iv12_3', 'ii1', 'ii2', 'ii3', 'ii3_1', 'ii4_1', 'ii4_2', 'ii4_3', 'ii5', 'ii5_1', 'ii6', 'ii6_1', 'ii7', 'ii7_esp', 'ii8', 'ii8_esp', 'ii9', 'v1', 'v2', 'v21', 'v22', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19_a', 'v19_b', 'ix_tot', 'ix_men10', 'ix_mayeq10', 'itf_y', 'decifr_y', 'idecifr_y', 'rdecifr_y', 'gdecifr_y', 'pdecifr_y', 'adecifr_y', 'ipcf_y', 'deccfr_y', 'ideccfr_y', 'rdeccfr_y', 'gdeccfr_y', 'pdeccfr_y', 'adeccfr_y', 'pondih_y', 'vii1_1', 'vii1_2', 'vii2_1', 'vii2_2', 'vii2_3', 'vii2_4', 'idimph']\n"
     ]
    }
   ],
   "source": [
    "# CONCATENO LAS BASES INDIVIDUAL Y HOGAR\n",
    "\n",
    "base_prelimpieza2 = pd.concat([base_ind_prelimpieza, base_hog_prelimpieza])\n",
    "base_prelimpieza2 = pd.merge(base_ind_prelimpieza, base_hog_prelimpieza, on = ['codusu', \"nro_hogar\"])\n",
    "\n",
    "print(base_prelimpieza2.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c1e3cbb-f911-4460-b2ff-049f02cf8621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " La cantidad de datos en la variable ch04 por valor de etiqueta \n",
      " ch04\n",
      "1    6814\n",
      "2    7550\n",
      "dtype: int64\n",
      "\n",
      " La cantidad de datos en la variable ch06 por valor de etiqueta \n",
      " ch06\n",
      "-1      51\n",
      " 0     120\n",
      " 1     170\n",
      " 2     189\n",
      " 3     176\n",
      "      ... \n",
      " 94      4\n",
      " 95      2\n",
      " 96      4\n",
      " 97      1\n",
      " 98      4\n",
      "Length: 100, dtype: int64\n",
      "\n",
      " La cantidad de datos en la variable ch07 por valor de etiqueta \n",
      " ch07\n",
      "1    2080\n",
      "2    3816\n",
      "3     790\n",
      "4     827\n",
      "5    6838\n",
      "9      13\n",
      "dtype: int64\n",
      "\n",
      " La cantidad de datos en la variable ch08 por valor de etiqueta \n",
      " ch08\n",
      "1     7817\n",
      "2     1161\n",
      "3       45\n",
      "4     5065\n",
      "9       36\n",
      "12     232\n",
      "13       3\n",
      "23       5\n",
      "dtype: int64\n",
      "\n",
      " La cantidad de datos en la variable nivel_ed por valor de etiqueta \n",
      " nivel_ed\n",
      "1    2192\n",
      "2    2300\n",
      "3    2729\n",
      "4    2658\n",
      "5    1576\n",
      "6    1748\n",
      "7    1161\n",
      "dtype: int64\n",
      "\n",
      " La cantidad de datos en la variable estado por valor de etiqueta \n",
      " estado\n",
      "0      51\n",
      "1    6195\n",
      "2     815\n",
      "3    5349\n",
      "4    1954\n",
      "dtype: int64\n",
      "\n",
      " La cantidad de datos en la variable cat_inac por valor de etiqueta \n",
      " cat_inac\n",
      "0    7061\n",
      "1    1379\n",
      "2      32\n",
      "3    2938\n",
      "4    1440\n",
      "5    1104\n",
      "6      99\n",
      "7     311\n",
      "dtype: int64\n",
      "\n",
      " La cantidad de datos en la variable componente por valor de etiqueta \n",
      " componente\n",
      "1     4787\n",
      "2     3811\n",
      "3     2560\n",
      "4     1665\n",
      "5      802\n",
      "6      356\n",
      "7      172\n",
      "8       99\n",
      "9       49\n",
      "10      26\n",
      "11      12\n",
      "12       8\n",
      "13       4\n",
      "14       1\n",
      "15       1\n",
      "51      11\n",
      "dtype: int64\n",
      "\n",
      " La cantidad de datos en la variable h15 por valor de etiqueta \n",
      " h15\n",
      "0     1954\n",
      "1    12359\n",
      "2       51\n",
      "dtype: int64\n",
      "\n",
      " La cantidad de datos en la variable mas_500 por valor de etiqueta \n",
      " mas_500\n",
      "0    14364\n",
      "dtype: int64\n",
      "\n",
      " La cantidad de datos en la variable aglomerado por valor de etiqueta \n",
      " aglomerado\n",
      "32     3205\n",
      "33    11159\n",
      "dtype: int64\n",
      "\n",
      " La cantidad de datos en la variable ch03 por valor de etiqueta \n",
      " ch03\n",
      "1     4854\n",
      "2     2769\n",
      "3     5442\n",
      "4      129\n",
      "5      525\n",
      "6      176\n",
      "7       57\n",
      "8      169\n",
      "9      175\n",
      "10      68\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tizip\\AppData\\Local\\Temp\\ipykernel_1608\\47215766.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  base_prelimpieza['ch04'] = base_prelimpieza['ch04'].replace({\n",
      "C:\\Users\\tizip\\AppData\\Local\\Temp\\ipykernel_1608\\47215766.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  base_prelimpieza['ch06'] = base_prelimpieza['ch06'].replace({\n",
      "C:\\Users\\tizip\\AppData\\Local\\Temp\\ipykernel_1608\\47215766.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  base_prelimpieza['ch07'] = base_prelimpieza['ch07'].replace({\n",
      "C:\\Users\\tizip\\AppData\\Local\\Temp\\ipykernel_1608\\47215766.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  base_prelimpieza['ch08'] = base_prelimpieza['ch08'].replace({\n",
      "C:\\Users\\tizip\\AppData\\Local\\Temp\\ipykernel_1608\\47215766.py:34: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  base_prelimpieza['nivel_ed'] = base_prelimpieza['nivel_ed'].replace({\n",
      "C:\\Users\\tizip\\AppData\\Local\\Temp\\ipykernel_1608\\47215766.py:44: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  base_prelimpieza['estado'] = base_prelimpieza['estado'].replace({\n",
      "C:\\Users\\tizip\\AppData\\Local\\Temp\\ipykernel_1608\\47215766.py:51: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  base_prelimpieza['cat_inac'] = base_prelimpieza['cat_inac'].replace({\n",
      "C:\\Users\\tizip\\AppData\\Local\\Temp\\ipykernel_1608\\47215766.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  base_prelimpieza['componente'] = base_prelimpieza['componente'].replace({\n",
      "C:\\Users\\tizip\\AppData\\Local\\Temp\\ipykernel_1608\\47215766.py:65: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  base_prelimpieza['h15'] = base_prelimpieza['h15'].replace({\n",
      "C:\\Users\\tizip\\AppData\\Local\\Temp\\ipykernel_1608\\47215766.py:70: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  base_prelimpieza['mas_500'] = base_prelimpieza['mas_500'].replace({\n",
      "C:\\Users\\tizip\\AppData\\Local\\Temp\\ipykernel_1608\\47215766.py:74: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  base_prelimpieza['aglomerado'] = base_prelimpieza['aglomerado'].replace({\n",
      "C:\\Users\\tizip\\AppData\\Local\\Temp\\ipykernel_1608\\47215766.py:78: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  base_prelimpieza['ch03'] = base_prelimpieza['ch03'].replace({\n"
     ]
    }
   ],
   "source": [
    "# como hay datos que tienen distintas etiquetas en las dos bases que concatenamos, tenemos que  renombrar las etiquetas de una de las bases asi se pueden tener todos los datos con el mismo valor\n",
    "variables_interes = base_prelimpieza[[\"ch04\", \"ch06\", \"ch07\", \"ch08\", \"nivel_ed\", \"estado\", \"cat_inac\", \"componente\", \"h15\", \"mas_500\", \"aglomerado\", \"ch03\"]]\n",
    "\n",
    "for i in variables_interes:\n",
    "    if i == \"ch04\": \n",
    "        base_prelimpieza['ch04'] = base_prelimpieza['ch04'].replace({\n",
    "            'Mujer': 2,\n",
    "            'Varón': 1})\n",
    "    elif i == \"ch06\":\n",
    "        base_prelimpieza['ch06'] = base_prelimpieza['ch06'].replace({\n",
    "            '98 y más años' : 98, \n",
    "            'Menos de 1 año' : 0})\n",
    "        # cambio el formato de los valores de esta columna porque la mitad estaba en float y la mitas en int\n",
    "        base_prelimpieza['ch06'] = base_prelimpieza['ch06'].astype(int)\n",
    "    elif i == \"ch07\":\n",
    "        base_prelimpieza['ch07'] = base_prelimpieza['ch07'].replace({\n",
    "            'Unido': 1, \n",
    "            'Casado': 2, \n",
    "            'Separado o divorciado': 3, \n",
    "            'Viudo': 4, \n",
    "            'Soltero': 5})\n",
    "    elif i == \"ch08\":\n",
    "        base_prelimpieza['ch08'] = base_prelimpieza['ch08'].replace({\n",
    "            'Obra social (incluye PAMI)': 1,  \n",
    "            'Mutual/Prepaga/Servicio de emergencia': 2,  \n",
    "            'Planes y seguros públicos': 3,  \n",
    "            'No paga ni le descuentan': 4,  \n",
    "            'Ns./Nr.': 9,  \n",
    "            'Obra social y mutual/prepaga/servicio de emergencia': 12,  \n",
    "            'Obra social y planes y seguros públicos': 13,  \n",
    "            'Mutual/prepaga/servicio de emergencia/planes y seguros públi': 23,\n",
    "            'Obra Social, mutual/prepaga/servicio de emergencia y planes y seguros públicos': 123})\n",
    "    elif i == \"nivel_ed\":\n",
    "        base_prelimpieza['nivel_ed'] = base_prelimpieza['nivel_ed'].replace({\n",
    "            'Primaria Incompleta (incluye educación especial)': 1,  \n",
    "            'Primaria Completa': 2,  \n",
    "            'Secundaria Incompleta': 3,  \n",
    "            'Secundaria Completa': 4,  \n",
    "            'Superior Universitaria Incompleta': 5,  \n",
    "            'Superior Universitaria Completa': 6, \n",
    "            'Sin instrucción': 7,  \n",
    "            'Ns./Nr.': 9})\n",
    "    elif i == \"estado\":\n",
    "        base_prelimpieza['estado'] = base_prelimpieza['estado'].replace({\n",
    "            'Ocupado': 1,  \n",
    "            'Desocupado': 2,  \n",
    "            'Inactivo': 3,  \n",
    "            'Menor de 10 años': 4,  \n",
    "            'Entrevista individual no realizada (no respuesta al cuestion': 0})\n",
    "    elif i == \"cat_inac\":\n",
    "        base_prelimpieza['cat_inac'] = base_prelimpieza['cat_inac'].replace({\n",
    "            0.0 : 0,\n",
    "            'Jubilado/pensionado': 1,  \n",
    "            'Rentista': 2,  \n",
    "            'Estudiante': 3,  \n",
    "            'Ama de casa': 4,  \n",
    "            'Menor de 6 años': 5,  \n",
    "            'Discapacitado': 6,  \n",
    "            'Otros': 7})\n",
    "    elif i == \"componente\":\n",
    "        base_prelimpieza['componente'] = base_prelimpieza['componente'].replace({\n",
    "            'Servicio doméstico en hogares': 51})\n",
    "        base_prelimpieza['componente'] = base_prelimpieza['componente'].astype(int)\n",
    "    elif i == \"h15\":\n",
    "        base_prelimpieza['h15'] = base_prelimpieza['h15'].replace({\n",
    "            \"Sí\": 1,\n",
    "            \"No\": 2})\n",
    "        base_prelimpieza['h15'] = base_prelimpieza['h15'].astype(int)\n",
    "    elif i == \"mas_500\":\n",
    "        base_prelimpieza['mas_500'] = base_prelimpieza['mas_500'].replace({\n",
    "            'N' : 1,\n",
    "            'S' : 0})\n",
    "    elif i == \"aglomerado\":\n",
    "        base_prelimpieza['aglomerado'] = base_prelimpieza['aglomerado'].replace({\n",
    "            'Ciudad de Buenos Aires' : 32,\n",
    "            'Partidos del GBA' : 33})\n",
    "    elif i == \"ch03\":\n",
    "        base_prelimpieza['ch03'] = base_prelimpieza['ch03'].replace({\n",
    "            'Jefe' : 1,\n",
    "            'Cónyuge/Pareja' : 2,\n",
    "            'Hijo/Hijastro' : 3,\n",
    "            'Yerno/Nuera' : 4,\n",
    "            'Nieto' : 5,\n",
    "            'Madre/Padre' : 6,\n",
    "            'Suegro' : 7,\n",
    "            'Hermano' : 8,\n",
    "            'Otros familiares' : 9,\n",
    "            'No familiares' : 10})\n",
    "    conteo = base_prelimpieza.groupby(i).size()\n",
    "    print(\"\\n\", \"La cantidad de datos en la variable\", i, \"por valor de etiqueta\", \"\\n\", conteo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45837c45-19c6-451f-a706-c10980353a66",
   "metadata": {},
   "source": [
    "### PUNTO 3\n",
    "Limpien la base de datos tomando criterios que hagan sentido. Explicar cualquier decisión como el tratamiento de valores faltantes (missing values), extremos (outliers), o variables categóricas. Justifique sus decisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "060d7c60-5047-4f9c-877b-a16d65cf3eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de valores negativos en variable edad: 51\n",
      "Cantidad: 14313\n",
      "Media: 36.12\n",
      "Desviacion estandar: 22.83\n",
      "Minimo: 0.00\n",
      "Maximo: 98.00\n"
     ]
    }
   ],
   "source": [
    "# VALORES NEGATIVOS EN EDAD\n",
    "\n",
    "valores_negativos_edad = base_prelimpieza['ch06'] < 0\n",
    "# Cantidad de datos negativos\n",
    "cantidad_negativos_edad = valores_negativos_edad.sum()\n",
    "print(\"Cantidad de valores negativos en variable edad:\", cantidad_negativos_edad)\n",
    "\n",
    "# Me quedo con los valores mayores o iguales a 0 de edad\n",
    "base_limpia = base_prelimpieza[base_prelimpieza['ch06'] >= 0]\n",
    "\n",
    "# Calcular cada estadística por separado\n",
    "count_ch06 = base_limpia['ch06'].count()\n",
    "mean_ch06 = base_limpia['ch06'].mean()\n",
    "std_ch06 = base_limpia['ch06'].std()\n",
    "min_ch06 = base_limpia['ch06'].min()\n",
    "max_ch06 = base_limpia['ch06'].max()\n",
    "\n",
    "# Mostrar las estadísticas\n",
    "print(f\"Cantidad: {count_ch06}\")\n",
    "print(f\"Media: {mean_ch06:.2f}\")\n",
    "print(f\"Desviacion estandar: {std_ch06:.2f}\")\n",
    "print(f\"Minimo: {min_ch06:.2f}\")\n",
    "print(f\"Maximo: {max_ch06:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75173cc-ed4d-42c6-a3c8-730d33bd0883",
   "metadata": {},
   "source": [
    "### PUNTO 4\n",
    "Construya variables (mínimo 3) que no estén en la base pero que sean relevantes para predecir individuos desocupados (por ejemplo, la proporción de personas que trabajan en el hogar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017d8fd-71e7-4269-80d3-c413749259ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2048b3df-14e4-4c93-b677-89b012e4eda2",
   "metadata": {},
   "source": [
    "### PUNTO 5\n",
    "Presenten estadísticas descriptivas de tres variables de la encuesta de hogar que ustedes creen que pueden ser relevantes para predecir la desocupación. Comenten las estadísticas obtenidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce242a-ed2c-42ff-a18f-c9bfa8810e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce745a86-6f30-42b4-8d56-45d2b3f3b6a4",
   "metadata": {},
   "source": [
    "## Parte II: Clasificación y regularización\n",
    "El objetivo de esta parte del trabajo es nuevamente intentar predecir si una persona está desocupada o no. Esta vez utilizando distintas variables de características individuales y del hogar del encuestado. A su vez, incluiremos ejercicios de regularización y de validación cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbee8e0-e96e-4aa4-bf97-4075f747939e",
   "metadata": {},
   "source": [
    "### PUNTO 1\n",
    "Para cada año, partan la base respondieron en una base de prueba y una de entrenamiento (X_train, y_train, X_test, y_test) utilizando el comando train_test_split. La base de entrenamiento debe comprender el 70% de los datos, y la semilla a utilizar (random state instance) debe ser 101. Establezca a desocupado como su variable dependiente en la base de entrenamiento (vector y). El resto de las variables serán las variables independientes (matriz X). Recuerden agregar la columna de unos (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e14bbf-aac7-4783-b6db-316e84a30600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e021f301-4300-465c-8d72-5cedcd2b0ea8",
   "metadata": {},
   "source": [
    "### PUNTO 2\n",
    "Expliquen brevemente cómo elegirían λ por validación cruzada (en Python es alpha). Detallen por qué no usarían el conjunto de prueba(test) para su elección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63229baf-a192-4f9e-b6a6-f04377cba752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc38cd07-0ef9-4907-864f-0764398e94a6",
   "metadata": {},
   "source": [
    "### PUNTO 3\n",
    "En validación cruzada, ¿cuáles son las implicancias de usar un k muy pequeño o uno muy grande? Cuando k = n (con n el número de muestras), ¿cuántas veces se estima el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bd1926-828b-4fa0-8775-8aa1c6d5496e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a0cac67-43fb-4924-8d5f-7b63593b6683",
   "metadata": {},
   "source": [
    "### PUNTO 4\n",
    "Para regresión logística, implementen la penalidad, L1 como la de LASSO y L2 comola de Ridge con (como en la Tutorial 10), usando λ = 1 la opción penalty y reporten la matriz de confusión, la curva ROC, los valores de AUC y de Accuracy para cada año (En la clase magistral 9, vimos el método de regularización en regresión lineal donde la variable dependiente es numérica. En este caso, nuestra variable dependiente es binaria (ocupado, desocupado), por lo que usamos la regresión logística y aprovechamos la opción de penalidad para aplicar los métodos de regularización vistos en clase.) ¿Cómo cambiaron los resultados con respecto al TP3? ¿La performance de regresión logística con regularización es mejor o peor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b42ee5-37f9-45bc-a6f0-d364e6cb0c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e10515bf-5586-4603-ad1c-a9f86f9f6c14",
   "metadata": {},
   "source": [
    "### PUNTO 5\n",
    "Realicen un barrido en = 10n con n ∈ {−5, −4, −3 ..., +4, +5} y utilicen 10-fold CV para elegir el óptimo en regresión logística con Ridge y con λ LASSO. ¿Qué seleccionó en cada caso? Usando la librería de seaborn, generen box plot mostrando la distribución del error de predicción para cada . Cada box debe corresponder a un valor de y contener como λ observaciones el error medio de validación (MSE) para cada partición. Además, para la regularización LASSO, generen un line plot del promedio de la proporción de variables ignoradas por el modelo en función de (como vieron en el tutorial 10), es decir la proporción de λ variables para las cuales el coeficiente asociado es cero (Hint: a mayor penalidad, esperamos que más coeficientes sean 0, por lo tanto, esta figura debe tener una forma de “S”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc9cd9-b4be-4881-9308-82635b94d48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18084909-4bde-46ce-828f-15b93858cb32",
   "metadata": {},
   "source": [
    "### PUNTO 6\n",
    "En el caso del valor óptimo de para LASSO encontrado en el inciso λ anterior, ¿qué variables fueron descartadas? ¿Son las que hubieran esperado? ¿Tiene relación con lo que respondieron en el inciso 1 de la Parte I?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e1eb6-034f-40b4-b388-3526beb452e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1266b28-4de9-45cd-8106-3f4da4cba74c",
   "metadata": {},
   "source": [
    "### PUNTO 7\n",
    "Elijan alguno de los modelos de regresión logística donde hayan probado distintos parámetros de regularización y comenten: Compare los resultados de 2004 versus 2024, ¿qué método de regularización funcionó mejor: Ridge o LASSO? ¿LASSO hizo una selección distinta de predictores en 2004 versus 2024? Comenten mencionando el error cuadrático medio (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e969f0a2-1c23-4aef-bf51-c87a0a6d31f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
