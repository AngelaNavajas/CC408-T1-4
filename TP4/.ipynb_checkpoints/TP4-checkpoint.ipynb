{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "370ed31d-cfba-4ea8-a3ae-ad372d2c3527",
   "metadata": {},
   "source": [
    "##  Parte I: Análisis de la base de hogares y tipo de ocupación\n",
    " Ahora que ya están familiarizados con la Encuesta Permanente de Hogares\n",
    " (EPH) y la desocupación, vamos a complejizar un poco la construcción de las\n",
    " tasas del desempleo. Relacionaremos la información a nivel hogar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf06b97-1597-4025-9c33-6fdd0eff08c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm     \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3bfe7f4-7a76-4ece-ab06-4c32302ac5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bases Tizi\n",
    "base_ind_04_sucia = pd.read_stata(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP3\\Individual_t104.dta\")\n",
    "base_ind_24_sucia = pd.read_excel(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP3\\usu_individual_T124.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f896b031-4044-4742-b3fa-96614e307a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hog_04_sucia = pd.read_stata(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP4\\Hogar_t104.dta\")\n",
    "base_hog_24_sucia = pd.read_excel(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP4\\usu_hogar_T124.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c7a4ec-2882-4b4c-815b-54ebb0635766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bases Angie\n",
    "#base_ind_04_sucia = pd.read_stata(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP3\\Individual_t104.dta\")\n",
    "#base_ind_24_sucia = pd.read_excel(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP3\\usu_individual_T124.xlsx\")\n",
    "\n",
    "#base_hog_04_sucia = pd.read_stata(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP4\\Hogar_t104.dta\")\n",
    "#base_hog_24_sucia = pd.read_excel(r\"C:\\Users\\tizip\\OneDrive\\Documentos\\Tizi UdeSA\\8- Ciencia de datos\\Compu nueva\\CC408-T1-4\\TP4\\usu_hogar_T124.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3d604-56cb-463a-9bac-36b8674cc2e1",
   "metadata": {},
   "source": [
    "### PUNTO 1\n",
    "Exploren el diseño de registro de la base de hogar: a priori, ¿qué variables creen pueden ser predictivas de la desocupación y seria útil incluir para perfeccionar el ejercicio del TP3? Mencionen estas variables y justifiquen su elección."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908092ec-4393-45f9-8a75-51f1b6b3b377",
   "metadata": {},
   "source": [
    "### PUNTO 2\n",
    "Descarguen la base de microdatos de la EPH correspondiente al primer trimestre de 2004 y 2024 en formato .dta y .xls, respectivamente. La base de hogares se llama Hogar_t104.dta y usu_hogar_T124.xls, respectivamente. Eliminen todas las observaciones que no corresponden a los aglomerados de Ciudad Autónoma de Buenos Aires o Gran Buenos Aires y unan ambos trimestres en una sola base. Esto es, a la base de la encuesta individual de cada año (que usaron en el TP3) unan la base de la encuesta de hogar. Asegúrese de estar usando las variables CODUSU y NRO_Hogar para el merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c3e870-92ab-4a0b-a74b-41a9bd70fe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['codusu', 'ano4', 'trimestre', 'nro_hogar', 'componente', 'h15', 'region', 'mas_500', 'aglomerado', 'pondera', 'ch03', 'ch04', 'ch05', 'ch06', 'ch07', 'ch08', 'ch09', 'ch10', 'ch11', 'ch12', 'ch13', 'ch14', 'ch15', 'ch15_cod', 'ch16', 'ch16_cod', 'nivel_ed', 'estado', 'cat_ocup', 'cat_inac', 'imputa', 'pp02c1', 'pp02c2', 'pp02c3', 'pp02c4', 'pp02c5', 'pp02c6', 'pp02c7', 'pp02c8', 'pp02e', 'pp02h', 'pp02i', 'pp03c', 'pp03d', 'pp3e_tot', 'pp3f_tot', 'pp03g', 'pp03h', 'pp03i', 'pp03j', 'intensi', 'pp04a', 'pp04b_cod', 'pp04b1', 'pp04b2', 'pp04b3_mes', 'pp04b3_ano', 'pp04b3_dia', 'pp04c', 'pp04c99', 'pp04d_cod', 'pp04g', 'pp05b2_mes', 'pp05b2_ano', 'pp05b2_dia', 'pp05c_1', 'pp05c_2', 'pp05c_3', 'pp05e', 'pp05f', 'pp05h', 'pp06a', 'pp06c', 'pp06d', 'pp06e', 'pp06h', 'pp07a', 'pp07c', 'pp07d', 'pp07e', 'pp07f1', 'pp07f2', 'pp07f3', 'pp07f4', 'pp07f5', 'pp07g1', 'pp07g2', 'pp07g3', 'pp07g4', 'pp07g_59', 'pp07h', 'pp07i', 'pp07j', 'pp07k', 'pp08d1', 'pp08d4', 'pp08f1', 'pp08f2', 'pp08j1', 'pp08j2', 'pp08j3', 'pp09a', 'pp09a_esp', 'pp09b', 'pp09c', 'pp09c_esp', 'pp10a', 'pp10c', 'pp10d', 'pp10e', 'pp11a', 'pp11b_cod', 'pp11b1', 'pp11b2_mes', 'pp11b2_ano', 'pp11b2_dia', 'pp11c', 'pp11c99', 'pp11d_cod', 'pp11g_ano', 'pp11g_mes', 'pp11g_dia', 'pp11l', 'pp11l1', 'pp11m', 'pp11n', 'pp11o', 'pp11p', 'pp11q', 'pp11r', 'pp11s', 'pp11t', 'p21', 'decocur', 'idecocur', 'rdecocur', 'gdecocur', 'pdecocur', 'adecocur', 'pondiio', 'tot_p12', 'p47t', 'decindr', 'idecindr', 'rdecindr', 'gdecindr', 'pdecindr', 'adecindr', 'pondii', 'v2_m', 'v3_m', 'v4_m', 'v5_m', 'v8_m', 'v9_m', 'v10_m', 'v11_m', 'v12_m', 'v18_m', 'v19_am', 'v21_m', 't_vi', 'itf', 'decifr', 'idecifr', 'rdecifr', 'gdecifr', 'pdecifr', 'adecifr', 'ipcf', 'deccfr', 'ideccfr', 'rdeccfr', 'gdeccfr', 'pdeccfr', 'adeccfr', 'pondih', 'pj1_1', 'pj2_1', 'pj3_1', 'idimpp']\n"
     ]
    }
   ],
   "source": [
    "# LIMPIO BASE INDIVIDUAL\n",
    "\n",
    "# me quedo solo con los valores de CABA y GBA\n",
    "base_ind_04_filtrada = base_ind_04_sucia.loc[base_ind_04_sucia['aglomerado'].isin(['Ciudad de Buenos Aires', 'Partidos del GBA'])]\n",
    "base_ind_24_filtrada = base_ind_24_sucia.loc[base_ind_24_sucia['AGLOMERADO'].isin([32, 33])]\n",
    "\n",
    "#Para poder unir sin problema, me aseguro que als variables esten en el mismo formato\n",
    "base_ind_04_filtrada.columns = base_ind_04_filtrada.columns.str.lower()\n",
    "base_ind_24_filtrada.columns = base_ind_24_filtrada.columns.str.lower()\n",
    "\n",
    "# concateno las bases\n",
    "base_ind_prelimpieza = pd.concat([base_ind_24_filtrada, base_ind_04_filtrada])\n",
    "print(base_ind_prelimpieza.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "642e442d-0b8f-4fdf-8f0b-9d7606b0c2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['codusu', 'ano4', 'trimestre', 'nro_hogar', 'realizada', 'region', 'mas_500', 'aglomerado', 'pondera', 'iv1', 'iv1_esp', 'iv2', 'iv3', 'iv3_esp', 'iv4', 'iv5', 'iv6', 'iv7', 'iv7_esp', 'iv8', 'iv9', 'iv10', 'iv11', 'iv12_1', 'iv12_2', 'iv12_3', 'ii1', 'ii2', 'ii3', 'ii3_1', 'ii4_1', 'ii4_2', 'ii4_3', 'ii5', 'ii5_1', 'ii6', 'ii6_1', 'ii7', 'ii7_esp', 'ii8', 'ii8_esp', 'ii9', 'v1', 'v2', 'v21', 'v22', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19_a', 'v19_b', 'ix_tot', 'ix_men10', 'ix_mayeq10', 'itf', 'decifr', 'idecifr', 'rdecifr', 'gdecifr', 'pdecifr', 'adecifr', 'ipcf', 'deccfr', 'ideccfr', 'rdeccfr', 'gdeccfr', 'pdeccfr', 'adeccfr', 'pondih', 'vii1_1', 'vii1_2', 'vii2_1', 'vii2_2', 'vii2_3', 'vii2_4', 'idimph']\n"
     ]
    }
   ],
   "source": [
    "# LIMPIO BASE HOGAR\n",
    "\n",
    "# me quedo solo con los valores de CABA y GBA\n",
    "base_hog_04_filtrada = base_hog_04_sucia.loc[base_hog_04_sucia['aglomerado'].isin(['Ciudad de Buenos Aires', 'Partidos del GBA'])]\n",
    "base_hog_24_filtrada = base_hog_24_sucia.loc[base_hog_24_sucia['AGLOMERADO'].isin([32, 33])]\n",
    "\n",
    "#Para poder unir sin problema, me aseguro que als variables esten en el mismo formato\n",
    "base_hog_04_filtrada.columns = base_hog_04_filtrada.columns.str.lower()\n",
    "base_hog_24_filtrada.columns = base_hog_24_filtrada.columns.str.lower()\n",
    "\n",
    "# concateno las bases\n",
    "base_hog_prelimpieza = pd.concat([base_hog_24_filtrada, base_hog_04_filtrada])\n",
    "print(base_hog_prelimpieza.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d65175-1388-4c0c-9813-8e4c0165b9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['codusu', 'ano4_x', 'trimestre_x', 'nro_hogar', 'componente', 'h15', 'region_x', 'mas_500_x', 'aglomerado_x', 'pondera_x', 'ch03', 'ch04', 'ch05', 'ch06', 'ch07', 'ch08', 'ch09', 'ch10', 'ch11', 'ch12', 'ch13', 'ch14', 'ch15', 'ch15_cod', 'ch16', 'ch16_cod', 'nivel_ed', 'estado', 'cat_ocup', 'cat_inac', 'imputa', 'pp02c1', 'pp02c2', 'pp02c3', 'pp02c4', 'pp02c5', 'pp02c6', 'pp02c7', 'pp02c8', 'pp02e', 'pp02h', 'pp02i', 'pp03c', 'pp03d', 'pp3e_tot', 'pp3f_tot', 'pp03g', 'pp03h', 'pp03i', 'pp03j', 'intensi', 'pp04a', 'pp04b_cod', 'pp04b1', 'pp04b2', 'pp04b3_mes', 'pp04b3_ano', 'pp04b3_dia', 'pp04c', 'pp04c99', 'pp04d_cod', 'pp04g', 'pp05b2_mes', 'pp05b2_ano', 'pp05b2_dia', 'pp05c_1', 'pp05c_2', 'pp05c_3', 'pp05e', 'pp05f', 'pp05h', 'pp06a', 'pp06c', 'pp06d', 'pp06e', 'pp06h', 'pp07a', 'pp07c', 'pp07d', 'pp07e', 'pp07f1', 'pp07f2', 'pp07f3', 'pp07f4', 'pp07f5', 'pp07g1', 'pp07g2', 'pp07g3', 'pp07g4', 'pp07g_59', 'pp07h', 'pp07i', 'pp07j', 'pp07k', 'pp08d1', 'pp08d4', 'pp08f1', 'pp08f2', 'pp08j1', 'pp08j2', 'pp08j3', 'pp09a', 'pp09a_esp', 'pp09b', 'pp09c', 'pp09c_esp', 'pp10a', 'pp10c', 'pp10d', 'pp10e', 'pp11a', 'pp11b_cod', 'pp11b1', 'pp11b2_mes', 'pp11b2_ano', 'pp11b2_dia', 'pp11c', 'pp11c99', 'pp11d_cod', 'pp11g_ano', 'pp11g_mes', 'pp11g_dia', 'pp11l', 'pp11l1', 'pp11m', 'pp11n', 'pp11o', 'pp11p', 'pp11q', 'pp11r', 'pp11s', 'pp11t', 'p21', 'decocur', 'idecocur', 'rdecocur', 'gdecocur', 'pdecocur', 'adecocur', 'pondiio', 'tot_p12', 'p47t', 'decindr', 'idecindr', 'rdecindr', 'gdecindr', 'pdecindr', 'adecindr', 'pondii', 'v2_m', 'v3_m', 'v4_m', 'v5_m', 'v8_m', 'v9_m', 'v10_m', 'v11_m', 'v12_m', 'v18_m', 'v19_am', 'v21_m', 't_vi', 'itf_x', 'decifr_x', 'idecifr_x', 'rdecifr_x', 'gdecifr_x', 'pdecifr_x', 'adecifr_x', 'ipcf_x', 'deccfr_x', 'ideccfr_x', 'rdeccfr_x', 'gdeccfr_x', 'pdeccfr_x', 'adeccfr_x', 'pondih_x', 'pj1_1', 'pj2_1', 'pj3_1', 'idimpp', 'ano4_y', 'trimestre_y', 'realizada', 'region_y', 'mas_500_y', 'aglomerado_y', 'pondera_y', 'iv1', 'iv1_esp', 'iv2', 'iv3', 'iv3_esp', 'iv4', 'iv5', 'iv6', 'iv7', 'iv7_esp', 'iv8', 'iv9', 'iv10', 'iv11', 'iv12_1', 'iv12_2', 'iv12_3', 'ii1', 'ii2', 'ii3', 'ii3_1', 'ii4_1', 'ii4_2', 'ii4_3', 'ii5', 'ii5_1', 'ii6', 'ii6_1', 'ii7', 'ii7_esp', 'ii8', 'ii8_esp', 'ii9', 'v1', 'v2', 'v21', 'v22', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19_a', 'v19_b', 'ix_tot', 'ix_men10', 'ix_mayeq10', 'itf_y', 'decifr_y', 'idecifr_y', 'rdecifr_y', 'gdecifr_y', 'pdecifr_y', 'adecifr_y', 'ipcf_y', 'deccfr_y', 'ideccfr_y', 'rdeccfr_y', 'gdeccfr_y', 'pdeccfr_y', 'adeccfr_y', 'pondih_y', 'vii1_1', 'vii1_2', 'vii2_1', 'vii2_2', 'vii2_3', 'vii2_4', 'idimph']\n"
     ]
    }
   ],
   "source": [
    "# CONCATENO LAS BASES INDIVIDUAL Y HOGAR\n",
    "\n",
    "base_prelimpieza = pd.concat([base_ind_prelimpieza, base_hog_prelimpieza])\n",
    "base_prelimpieza = pd.merge(base_ind_prelimpieza, base_hog_prelimpieza, on = ['codusu', \"nro_hogar\"])\n",
    "\n",
    "print(base_prelimpieza.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45837c45-19c6-451f-a706-c10980353a66",
   "metadata": {},
   "source": [
    "### PUNTO 3\n",
    "Limpien la base de datos tomando criterios que hagan sentido. Explicar cualquier decisión como el tratamiento de valores faltantes (missing values), extremos (outliers), o variables categóricas. Justifique sus decisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d7c60-5047-4f9c-877b-a16d65cf3eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f75173cc-ed4d-42c6-a3c8-730d33bd0883",
   "metadata": {},
   "source": [
    "### PUNTO 4\n",
    "Construya variables (mínimo 3) que no estén en la base pero que sean relevantes para predecir individuos desocupados (por ejemplo, la proporción de personas que trabajan en el hogar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017d8fd-71e7-4269-80d3-c413749259ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2048b3df-14e4-4c93-b677-89b012e4eda2",
   "metadata": {},
   "source": [
    "### PUNTO 5\n",
    "Presenten estadísticas descriptivas de tres variables de la encuesta de hogar que ustedes creen que pueden ser relevantes para predecir la desocupación. Comenten las estadísticas obtenidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce242a-ed2c-42ff-a18f-c9bfa8810e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce745a86-6f30-42b4-8d56-45d2b3f3b6a4",
   "metadata": {},
   "source": [
    "## Parte II: Clasificación y regularización\n",
    "El objetivo de esta parte del trabajo es nuevamente intentar predecir si una persona está desocupada o no. Esta vez utilizando distintas variables de características individuales y del hogar del encuestado. A su vez, incluiremos ejercicios de regularización y de validación cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbee8e0-e96e-4aa4-bf97-4075f747939e",
   "metadata": {},
   "source": [
    "### PUNTO 1\n",
    "Para cada año, partan la base respondieron en una base de prueba y una de entrenamiento (X_train, y_train, X_test, y_test) utilizando el comando train_test_split. La base de entrenamiento debe comprender el 70% de los datos, y la semilla a utilizar (random state instance) debe ser 101. Establezca a desocupado como su variable dependiente en la base de entrenamiento (vector y). El resto de las variables serán las variables independientes (matriz X). Recuerden agregar la columna de unos (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e14bbf-aac7-4783-b6db-316e84a30600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e021f301-4300-465c-8d72-5cedcd2b0ea8",
   "metadata": {},
   "source": [
    "### PUNTO 2\n",
    "Expliquen brevemente cómo elegirían λ por validación cruzada (en Python es alpha). Detallen por qué no usarían el conjunto de prueba(test) para su elección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63229baf-a192-4f9e-b6a6-f04377cba752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc38cd07-0ef9-4907-864f-0764398e94a6",
   "metadata": {},
   "source": [
    "### PUNTO 3\n",
    "En validación cruzada, ¿cuáles son las implicancias de usar un k muy pequeño o uno muy grande? Cuando k = n (con n el número de muestras), ¿cuántas veces se estima el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bd1926-828b-4fa0-8775-8aa1c6d5496e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a0cac67-43fb-4924-8d5f-7b63593b6683",
   "metadata": {},
   "source": [
    "### PUNTO 4\n",
    "Para regresión logística, implementen la penalidad, L1 como la de LASSO y L2 comola de Ridge con (como en la Tutorial 10), usando λ = 1 la opción penalty y reporten la matriz de confusión, la curva ROC, los valores de AUC y de Accuracy para cada año (En la clase magistral 9, vimos el método de regularización en regresión lineal donde la variable dependiente es numérica. En este caso, nuestra variable dependiente es binaria (ocupado, desocupado), por lo que usamos la regresión logística y aprovechamos la opción de penalidad para aplicar los métodos de regularización vistos en clase.) ¿Cómo cambiaron los resultados con respecto al TP3? ¿La performance de regresión logística con regularización es mejor o peor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b42ee5-37f9-45bc-a6f0-d364e6cb0c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e10515bf-5586-4603-ad1c-a9f86f9f6c14",
   "metadata": {},
   "source": [
    "### PUNTO 5\n",
    "Realicen un barrido en = 10n con n ∈ {−5, −4, −3 ..., +4, +5} y utilicen 10-fold CV para elegir el óptimo en regresión logística con Ridge y con λ LASSO. ¿Qué seleccionó en cada caso? Usando la librería de seaborn, generen box plot mostrando la distribución del error de predicción para cada . Cada box debe corresponder a un valor de y contener como λ observaciones el error medio de validación (MSE) para cada partición. Además, para la regularización LASSO, generen un line plot del promedio de la proporción de variables ignoradas por el modelo en función de (como vieron en el tutorial 10), es decir la proporción de λ variables para las cuales el coeficiente asociado es cero (Hint: a mayor penalidad, esperamos que más coeficientes sean 0, por lo tanto, esta figura debe tener una forma de “S”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc9cd9-b4be-4881-9308-82635b94d48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18084909-4bde-46ce-828f-15b93858cb32",
   "metadata": {},
   "source": [
    "### PUNTO 6\n",
    "En el caso del valor óptimo de para LASSO encontrado en el inciso λ anterior, ¿qué variables fueron descartadas? ¿Son las que hubieran esperado? ¿Tiene relación con lo que respondieron en el inciso 1 de la Parte I?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e1eb6-034f-40b4-b388-3526beb452e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1266b28-4de9-45cd-8106-3f4da4cba74c",
   "metadata": {},
   "source": [
    "### PUNTO 7\n",
    "Elijan alguno de los modelos de regresión logística donde hayan probado distintos parámetros de regularización y comenten: Compare los resultados de 2004 versus 2024, ¿qué método de regularización funcionó mejor: Ridge o LASSO? ¿LASSO hizo una selección distinta de predictores en 2004 versus 2024? Comenten mencionando el error cuadrático medio (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e969f0a2-1c23-4aef-bf51-c87a0a6d31f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
